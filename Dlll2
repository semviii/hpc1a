import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
import matplotlib.pyplot as plt




# Load the IMDB dataset. It already contains preprocessed integer-encoded data.
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)

# The dataset is represented as sequences of integers, where each integer represents a word in the vocabulary.

# Pad the sequences so that they are all the same length. This step is necessary for neural networks.
maxlen = 500 # We will consider the first 500 words in each review
x_train = pad_sequences(x_train, maxlen=maxlen)
x_test = pad_sequences(x_test, maxlen=maxlen)

print(f"Training data shape: {x_train.shape}, Test data shape: {x_test.shape}")


model = models.Sequential()

# Embedding layer converts integer-encoded words to dense vectors of fixed size
model.add(layers.Embedding(input_dim=10000, output_dim=128, input_length=maxlen))

# Add a Flatten layer to flatten the output of the embedding layer into a 1D array
model.add(layers.GlobalAveragePooling1D())

# Add a Dense layer with ReLU activation function
model.add(layers.Dense(64, activation='relu'))

# Add a Dense layer with 1 output neuron, with sigmoid activation for binary classification
model.add(layers.Dense(1, activation='sigmoid'))




# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


#Train the model
history = model.fit(x_train, y_train, epochs=5, batch_size=512, validation_data=(x_test, y_test))


#Evaluate the model
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")




# Plot training & validation accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()


# Plot training & validation loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()


# Predict a single review
sample_review = x_test[0] # Take the first test sample
prediction = model.predict(sample_review.reshape(1, -1)) # Make a prediction for this sample
print(f"Prediction: {prediction}")
    
